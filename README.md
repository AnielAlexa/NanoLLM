# NanoLLM
<a href="https://www.jetson-ai-lab.com"><img align="right" width="200" height="200" src="https://nvidia-ai-iot.github.io/jetson-generative-ai-playground/images/JON_Gen-AI-panels.png"></a>

Optimized local inference for LLMs with HuggingFace-like APIs for quantization, vision/language models, multimodal agents, speech, vector DB, and RAG.

> [!NOTE]  
> See [`dusty-nv.github.io/NanoLLM`](https://dusty-nv.github.io/NanoLLM) for docs and [**Jetson AI Lab**](https://www.jetson-ai-lab.com) for tutorials.
> &nbsp;&nbsp;<br/><br/>  
> Latest Release:  [24.5.1](https://dusty-nv.github.io/NanoLLM/releases.html)  ([`dustynv/nano_llm:24.5.1-r36.2.0`](https://hub.docker.com/r/dustynv/nano_llm/tags)) <br/> 
> Latest Build: [main](https://dusty-nv.github.io/NanoLLM/releases.html)  ([`dustynv/nano_llm:r36.2.0`](https://hub.docker.com/r/dustynv/nano_llm/tags))
